{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs sentiment analysis on movie reviews from the IMDb dataset using a LSTM (Long Short-Term Memory) model. It predicts whether a review is positive or negative based on textual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Keras Modules:\n",
    "\n",
    "    Sequential: For building the model layer by layer.\n",
    "    Dense: Fully connected layer for binary classification.\n",
    "    LSTM: Recurrent layer for sequence processing.\n",
    "    Embedding: Embedding layer to represent words as dense vectors.\n",
    "    imdb: Provides the IMDb dataset for sentiment analysis.\n",
    "    pad_sequences: Ensures all input sequences are of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 12:16:16.097636: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-12 12:16:16.106593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-12 12:16:16.117964: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-12 12:16:16.121205: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-12 12:16:16.130465: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-12 12:16:16.739069: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setteng parameters\n",
    "max_features: Limits the vocabulary to the top 5000 most frequent words.\n",
    "max_len: Maximum number of words in each review (longer reviews are truncated, shorter ones are padded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000  # Vocabulary size\n",
    "max_len = 100  # Max sequence length\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train, X_test: Sequences of word indices representing reviews.\n",
    "y_train, y_test: Sentiment labels (0 for negative, 1 for positive).\n",
    "Pads or truncates sequences to ensure uniform length (max_len)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word_index: Maps words to their indices.\n",
    "reverse_word_index: Inverts the mapping (indices → words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = {value: key for key, value in word_index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts sequences of word indices back into human-readable text.\n",
    "Adjusts for special tokens (offset by -3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_review(sequence):\n",
    "    \"\"\"Convert a sequence of integers into a human-readable review.\"\"\"\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in sequence if i > 2])  # Offset for special tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding Layer:\n",
    "\n",
    "    Maps each word index to a dense vector of size 128.\n",
    "    Handles a vocabulary size of max_features.\n",
    "\n",
    "LSTM Layer:\n",
    "\n",
    "    64 units for processing sequential input.\n",
    "    Dropout (20%) and recurrent dropout (20%) prevent overfitting.\n",
    "\n",
    "Dense Layer:\n",
    "\n",
    "    Single neuron with sigmoid activation for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshita/miniconda3/envs/ML/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(max_features, 128, input_length=max_len),\n",
    "    LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer: adam for adaptive learning.\n",
    "Loss Function: Binary cross-entropy for binary classification.\n",
    "Metrics: Accuracy to measure performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate: Tests the model on unseen data (X_test, y_test).\n",
    "Outputs: Test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.4917 - loss: 0.6933\n",
      "Test Accuracy: 0.495959997177124\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates probabilities (0 to 1) for each review's sentiment:\n",
    "\n",
    "        0.5 → Positive sentiment.\n",
    "\n",
    "    ≤0.5 → Negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop: Processes the first 5 reviews in the test set.\n",
    "decode_review: Converts the numerical sequence into text.\n",
    "Compare: Shows predicted vs. actual sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Reviews with Predictions:\n",
      "\n",
      "Review 1: please give this one a miss br br and the rest of the cast terrible performances the show is flat flat flat br br i don't know how michael could have allowed this one on his he almost seemed to know this wasn't going to work out and his performance was quite so all you fans give this a miss\n",
      "Predicted Sentiment: Negative\n",
      "Actual Sentiment: Negative\n",
      "\n",
      "Review 2: a powerful study of sexual and desperation be patient up the atmosphere and pay attention to the wonderfully written script br br i praise robert this is one of his many films that deals with fascinating subject matter this film is disturbing but it's sincere and it's sure to a strong emotional response from the viewer if you want to see an unusual film some might even say bizarre this is worth the time br br unfortunately it's very difficult to find in video you may have to buy it off the internet\n",
      "Predicted Sentiment: Positive\n",
      "Actual Sentiment: Positive\n",
      "\n",
      "Review 3: the of that civil war it would be easy to see this as a about those events may or may not have had in mind when he made but whatever his choice of material the film stands as a tale of universal could be the soviet union italy germany or japan in the 1930s or any country of any era that lets its guard down and is by it's a fascinating film even a charming one in its way but its message is no joke\n",
      "Predicted Sentiment: Negative\n",
      "Actual Sentiment: Positive\n",
      "\n",
      "Review 4: the mother in this movie is with her children to the point of i wish i wasn't so angry about her and her actions because i would have otherwise enjoyed the flick what a number she was take my advise and fast forward through everything you see her do until the end also is anyone else getting sick of watching movies that are filmed so dark anymore one can hardly see what is being filmed as an audience we are involved with the actions on the screen so then why the hell can't we have night vision\n",
      "Predicted Sentiment: Positive\n",
      "Actual Sentiment: Negative\n",
      "\n",
      "Review 5: die hard mario fan and i loved this game br br this game starts slightly boring but trust me it's worth it as soon as you start your hooked the levels are fun and they will hook you your mind turns to i'm not kidding this game is also and is beautifully done br br to keep this spoiler free i have to keep my mouth shut about details but please try this game it'll be worth it br br story 9 9 action 10 1 it's that good 10 attention 10 average 10\n",
      "Predicted Sentiment: Negative\n",
      "Actual Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSample Reviews with Predictions:\")\n",
    "for i in range(5):\n",
    "    decoded_review = decode_review(X_test[i])  # Decode the review\n",
    "    predicted_sentiment = \"Positive\" if predictions[i] > 0.5 else \"Negative\"\n",
    "    actual_sentiment = \"Positive\" if y_test[i] == 1 else \"Negative\"\n",
    "    print(f\"\\nReview {i + 1}: {decoded_review}\")\n",
    "    print(f\"Predicted Sentiment: {predicted_sentiment}\")\n",
    "    print(f\"Actual Sentiment: {actual_sentiment}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
